import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import pandas as pd
# import matplotlib
# matplotlib.use('Qt5Agg')

EPSILON = 0.001
MAX_ITER = 10000


def main():
    plot_function()
    point_result1 = gradient_descent(1, 2, MAX_ITER, 0.01)
    plot_learning_points(point_result1)
    # print(point_result1)
    #
    point_result2 = gradient_descent(1, 2, MAX_ITER, 0.5)
    plot_learning_points(point_result2)
    # print(point_result2)

    point_result3 = gradient_descent(1, 2, MAX_ITER, 10)
    plot_learning_points(point_result3)


def plot_function():
    """
    Plot the function:

    .. math:: f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 3)^2
    """
    x1 = np.linspace(0, 5, 50)
    x2 = np.linspace(0, 5, 50)
    X1, X2 = np.meshgrid(x1, x2)
    Y = f(X1, X2)
    fig = plt.figure()
    ax = plt.axes(projection='3d')
    ax.plot_surface(X1, X2, Y, rstride=1, cstride=1, cmap='viridis', edgecolor='none')
    ax.set_xlabel('x1')
    ax.set_ylabel('x2')
    ax.set_zlabel('y')
    plt.show()


def gradient_descent(x1_0, x2_0, max_iter, rho):
    """
    This function runs gradient descent.
    :param x1_0: initial x1
    :param x2_0: initial x2
    :param max_iter: max number of iteration
    :param rho: learning rate
    :return:
    """
    point_list = [np.array([x1_0, x2_0, f(x1_0, x2_0)])]
    curr_point = np.array([x1_0, x2_0, 0])
    for i in range(0, max_iter):
        new_point, new_dir = single_descent(curr_point, rho)
        point_list += [new_point]
        curr_point = new_point

        if np.linalg.norm(new_dir) < EPSILON:
            print("The total number of iterations is: {}".format(i + 1))
            return point_list
        elif np.any(np.isinf(curr_point)):
            print("It reaches infinite, does not converge!\n"
                  "The total number of iterations is: {}".format(i + 1))
            return point_list
    print("Exceeds max iteration: {}; with learning rate: {}".format(max_iter, rho))
    return point_list


def single_descent(point, rho):
    """
    This function
    :param point: The current point
    :param rho: The learning rate
    :return: The next point and the moving direction
    """
    x1 = point[0]
    x2 = point[1]
    x1_dir = 2. * (x1 - 2.)
    x2_dir = 2. * (x2 - 3.)
    new_x1 = x1 - x1_dir * rho
    new_x2 = x2 - x2_dir * rho
    new_y = f(new_x1, new_x2)
    return np.array([new_x1, new_x2, new_y]), np.array([x1_dir, x2_dir])


def f(x1, x2):
    """
    Find y from function f(x1,x2) = (x1 - 2)^2 + (x2 - 3)^2
    :param x1: input x1
    :param x2: input x2
    :return: f(x1,x2)
    """
    return np.power(x1 - 2., 2) + np.power(x2 - 3., 2)


def plot_learning_points(points):
    """
    Plot the points sequence generated by gradient descent
    :param points: Input points generated from gradient descent
    """
    df = pd.DataFrame(points, columns=['x1', 'x2', 'y'])
    df = df.replace([np.inf, -np.inf], np.nan).dropna()
    xs = df['x1'].values.tolist()
    ys = df['x2'].values.tolist()
    zs = df['y'].values.tolist()
    ax = plt.axes(projection='3d')
    ax.scatter3D(xs, ys, zs, c=zs)
    ax.plot3D(xs, ys, zs, 'gray')
    ax.set_xlabel('x_1')
    ax.set_ylabel('x_2')
    ax.set_zlabel('y')
    plt.show()


if __name__ == "__main__":
    main()
